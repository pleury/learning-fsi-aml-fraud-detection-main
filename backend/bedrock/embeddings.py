import json
import os
import logging
from typing import Optional, List

from .client import BedrockClient
from botocore.exceptions import ClientError
from dotenv import load_dotenv

load_dotenv()

# Set up logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


class BedrockTitanEmbeddings(BedrockClient):
    """ A class to generate text embeddings using the Amazon Titan Embeddings model. """
    # References:
    # https://docs.aws.amazon.com/bedrock/latest/userguide/model-parameters-embeddings.html

    log: logging.Logger = logging.getLogger("BedrockTitanEmbeddings")

    def __init__(self, aws_access_key: Optional[str] = None, aws_secret_key: Optional[str] = None,
                 region_name: Optional[str] = "eu-west-3", model_id: Optional[str] = "amazon.titan-embed-text-v1") -> None:
        super().__init__(aws_access_key=aws_access_key, aws_secret_key=aws_secret_key, region_name=region_name)
        """
        Initialize the BedrockTitanEmbeddings class.
        
        Args:
            aws_access_key (str): The AWS access key.
            aws_secret_key (str): The AWS secret key.
            region_name (str): The AWS region name.
            model_id (str): The model ID to use. Default is Amazon Titan Embeddings model.
        """
        self.model_id = model_id
        self.bedrock_client = self._get_bedrock_client()

    def generate_text_embeddings(self, body: str):
        """
        Generate text embedding by using the Titan Embed model.
        Args:
            body (str): The request body to use.
        Returns:
            dict: The response from the model.
        """
        accept = '*/*'
        content_type = 'application/json'

        response = self.bedrock_client.invoke_model(
            body=body,
            modelId=self.model_id,
            accept=accept,
            contentType=content_type
        )

        return response

    def predict(self, text: str) -> List[float]:
        """ Predict text embeddings based on the input text. 

        Args:
            text (str): The input text to generate embeddings for.

        Returns:
            list: The text embeddings generated by the model.
        """
        try:
            # Titan model format is different from Cohere
            body = json.dumps({
                "inputText": text
            })
            response = self.generate_text_embeddings(body=body)
            
            # Extract the response embeddings
            response_body = json.loads(response.get('body').read())
            embedding = response_body.get("embedding")
            
            if not embedding:
                self.log.error("No embedding found in response: %s", response_body)
                raise ValueError("No embedding found in response")
                
            return embedding
        except ClientError as err:
            message = err.response["Error"]["Message"]
            self.log.error("A client error occurred: %s", message)
            raise


# Singleton instance for reuse across API calls
_embedding_model = None


def get_embedding_model():
    """
    Get or create a singleton instance of the BedrockTitanEmbeddings class.
    This helps avoid creating new clients for each API call.
    
    Returns:
        BedrockTitanEmbeddings: The embedding model instance.
    """
    global _embedding_model
    
    if _embedding_model is None:
        aws_access_key = os.getenv("AWS_ACCESS_KEY_ID")
        aws_secret_key = os.getenv("AWS_SECRET_ACCESS_KEY")
        region_name = os.getenv("AWS_REGION")
        
        _embedding_model = BedrockTitanEmbeddings(
            model_id="amazon.titan-embed-text-v1",
            region_name=region_name,
            aws_access_key=aws_access_key,
            aws_secret_key=aws_secret_key
        )
    
    return _embedding_model


async def get_embedding(text: str) -> List[float]:
    """
    Generate embeddings for the given text using Amazon Bedrock Titan model.
    
    Args:
        text (str): The text to generate embeddings for.
        
    Returns:
        List[float]: The embeddings vector.
        
    Raises:
        Exception: If there's an error generating the embeddings.
    """
    try:
        model = get_embedding_model()
        embeddings = model.predict(text)
        return embeddings
    except Exception as e:
        logger.error(f"Error generating embeddings with Titan model: {str(e)}")
        raise


async def get_batch_embeddings(texts: List[str]) -> List[List[float]]:
    """
    Generate embeddings for a batch of texts.
    
    Args:
        texts (List[str]): List of texts to generate embeddings for.
        
    Returns:
        List[List[float]]: List of embedding vectors.
    """
    results = []
    for text in texts:
        embedding = await get_embedding(text)
        results.append(embedding)
    return results


if __name__ == '__main__':
    import asyncio
    
    # Example usage
    aws_access_key = os.getenv("AWS_ACCESS_KEY_ID")
    aws_secret_key = os.getenv("AWS_SECRET_ACCESS_KEY")
    region_name = os.getenv("AWS_REGION")

    # Direct usage of the class
    embeddings_client = BedrockTitanEmbeddings(
        region_name=region_name,
        aws_access_key=aws_access_key,
        aws_secret_key=aws_secret_key
    )

    # Test direct prediction
    sample_text = "This is a sample text for fraud detection in financial transactions."
    result = embeddings_client.predict(sample_text)
    print(f"Direct embedding result (first 5 values): {result[:5]}... (total length: {len(result)})")
    
    # Test the async wrapper function
    async def test_get_embedding():
        result = await get_embedding("Suspicious login from new IP address followed by large wire transfer.")
        print(f"Async embedding result (first 5 values): {result[:5]}... (total length: {len(result)})")
        
        batch_results = await get_batch_embeddings([
            "Customer account accessed from unusual location", 
            "Multiple failed login attempts before successful authentication"
        ])
        print(f"Batch embedding results: {len(batch_results)} embeddings generated")
    
    # Run the async test
    asyncio.run(test_get_embedding())
